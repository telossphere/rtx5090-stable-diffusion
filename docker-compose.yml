version: "3.8"

services:
  stable-diffusion:
    build:
      context: .
      dockerfile: Dockerfile
    image: stable-diffusion-rtx5090:latest
    container_name: stable-diffusion-rtx5090
    restart: unless-stopped
    ports:
      - "7860:7860"
    volumes:
      - ./models/stable-diffusion:/opt/ai/models/stable-diffusion
      - ./models/huggingface:/opt/ai/huggingface
      - ./config/stable-diffusion:/workspace/webui/config
      - ./logs/stable-diffusion:/workspace/webui/logs
      - ./outputs:/workspace/webui/outputs
    environment:
      - DEBIAN_FRONTEND=noninteractive
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - CUDA_VISIBLE_DEVICES=0
      - PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:1024
      - TF_FORCE_GPU_ALLOW_GROWTH=true
      - CUDA_LAUNCH_BLOCKING=0
      - TORCH_CUDNN_V8_API_ENABLED=1
      - SD_WEBUI_MAX_BATCH_COUNT=8
      - SD_WEBUI_MAX_BATCH_SIZE=8
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
        limits:
          memory: 30G

volumes:
  stable-diffusion-config:
    driver: local
  stable-diffusion-outputs:
    driver: local
